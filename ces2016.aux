\relax 
\citation{WHOvisuallyimpaired}
\citation{something}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Applications and underlying technoloigies}}{1}}
\newlabel{fig:introduction}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Platform and Interfaces}{1}}
\newlabel{sec:interfaces}{{II}{1}}
\citation{iPhone}
\citation{Bengio2009}
\citation{DNNNature2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Interfaces}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Using the System}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Beyond Deep Learning: Pragmatic Optimizations for Constrained Resources and Limited Time}{2}}
\newlabel{sec:vision}{{III}{2}}
\citation{facenet}
\citation{Bruceb}
\citation{hop}
\citation{estimedia2015}
\citation{stein2009neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Visual Attention}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Saliency used for missplaced item detection.}}{3}}
\newlabel{tab:saliencya}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Redundancy}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Context}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Multimodal Fusion}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Hardware Support}{3}}
\newlabel{sec:hardware}{{IV}{3}}
\citation{fpl2015}
\citation{fpl2015}
\citation{truenorth}
\citation{truenorth}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Saliency and SURF used to identify similar items.}}{4}}
\newlabel{tab:saliencyb}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Spatial relations exist between frequently co-occurring objects. These relationships can then be used as context cues to guide the recognition task.}}{4}}
\newlabel{fig:viconet}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Custom Chips}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Brain-like Architectures}{4}}
\citation{upitt}
\citation{wtsai}
\citation{redeye}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,library}
\bibcite{iPhone}{1}
\bibcite{Bengio2009}{2}
\bibcite{DNNNature2015}{3}
\bibcite{facenet}{4}
\bibcite{Bruceb}{5}
\bibcite{hop}{6}
\bibcite{estimedia2015}{7}
\bibcite{stein2009neural}{8}
\bibcite{fpl2015}{9}
\bibcite{truenorth}{10}
\bibcite{upitt}{11}
\bibcite{wtsai}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Temporal sensor information used for localization.}}{5}}
\newlabel{tab:sensor}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Emerging Devices}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{5}}
\newlabel{sec:conclusion}{{V}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
\bibcite{redeye}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Coupling structured features with learned features}}{6}}
\newlabel{fig:customchips}{{6}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Mapping HOG to True North}}{6}}
\newlabel{tab:tn}{{7}{6}}
\@writefile{toc}{\contentsline {section}{Biographies}{6}}
\@writefile{toc}{\contentsline {subsection}{Peter Zientara}{6}}
\@writefile{toc}{\contentsline {subsection}{Siddharth Advani}{6}}
\@writefile{toc}{\contentsline {subsection}{John (Jack) Sampson}{6}}
\@writefile{toc}{\contentsline {subsection}{Vijaykrishnan Narayanan}{6}}
