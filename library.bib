@article{siagian,
author = {Siagian, C. and Itti, L.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {{Rapid Biologically-Inspired Scene Classification Using Features with Shared Visual Attention}},
year = {2007}
}

@inproceedings{lijia, 
author={Li, L. and Socher, R. and Fei-Fei, L.}, 
booktitle={Computer Vision and Pattern Recognition (CVPR)}, 
title={Towards Total Scene Understanding: Classification, Annotation and Segmentation in an Automatic Framework}, 
year={2009}, 
month={June}
}

@article{google, 
author={Page, L. and Brin S.}, 
journal = {Computer Networks and ISDN Systems},
title={The anatomy of a large-scale hypertextual Web search engine},
year={1998}
}

@inproceedings{torralba, 
author={Torralba, A. and Murphy, K. P. and Freeman, W. T. and Rubin, M. A.}, 
booktitle={IEEE Intl. Conference on Computer Vision (ICCV)}, 
title={Context-Based Vision System for Place and Object Recognition}, 
year={2003}, 
month={October}
}

@inproceedings{rabinovich, 
author={Rabinovich, A.}, 
booktitle={IEEE Intl. Conference on Computer Vision (ICCV)}, 
title={Objects in Context}, 
year={2007}
}

@inproceedings{yusu, 
author={Su, Y. and Jurie, F.}, 
booktitle={IEEE Intl. Conference on Computer Vision (ICCV)}, 
title={Visual Word Disambiguation by Semantic Contexts}, 
year={2011}, 
month={November}
}

@inproceedings{eccv,
    author    = "Marian George and Christian Floerkemeier",
    title     = "Recognizing Products: A Per-Exemplar Multi-Label Image Classification Approach",
    booktitle = "European Conference on Computer Vision (ECCV)",
    year      = "2014",
    month     = "September"
}

@Misc{Sinofsky,
 author = {Steven Sinofsky},
 howpublished = {2009 Windows 7 Energy Efficiency}
}

@electronic{inria,
 title = {{INRIA} Person Dataset},
 url = {http://pascal.inrialpes.fr/data/human/}, 
 note={(Date last accessed 16-Sep-2016)}
}

@electronic{who,
 title = {World Health Organization},
 url = {http://www.who.int/mediacentre/factsheets/fs282/en/}, 
 note={(Date last accessed 16-Sep-2016)}
}

@electronic{ethz,
 title = {{Robust Multi-Person Tracking from Mobile Platforms}},
 url = {https://data.vision.ee.ethz.ch/cvl/aess/dataset/}, 
 note={(Date last accessed 16-Sep-2016)}
}

@electronic{XilinxEmbeddedVision,
title={{Embedded Vision: FPGA's Next Notable Technology Opportunity}},
url={http://www.xilinx.com/publications/archives/xcell/Xcell78.pdf}},
note={(Date last accessed 24-Jun-2016)}
}

@electronic{iPhone,
 title = {{iPhone 6s/6s Plus}},
 url = {http://www.apple.com/iphone-6s/specs/}, 
 note={(Date last accessed 29-Jan-2016)}
}

@electronic{Samsung,
 title = {{Samsung}}, 
 url = {http://www.samsung.com/us/video/tvs/},
 note={(Date last accessed 29-Jan-2016)} 
}

@electronic{SamsungPhone,
 title = {{Samsung Galaxy}},
 url = {http://www.gsmarena.com/samsung_galaxy_core_prime-6716.php},
 note = {(Date last accessed 20-Jun-2016)}
 }

@electronic{Caffe4Android,
 title = {{Caffe for Android}},
 url = {https://github.com/sh1r0/caffe-android-lib},
 note = {(Date last accessed 20-Jun-2016)}
}

@electronic{Cadence,
  title={Using Convolutional Neural Networks for Image Recognition},
  url = {http://ip.cadence.com/uploads/901/cnn_wp-pdf},
  note ={(Date last accessed 12-Jun-2016)},
  author={Hijazi, Samer and Kumar, Rishi and Rowen, Chris}
}

@electronic{RealSense, 
 title={RealSense},
 url={http://www.intel.com/content/www/us/en/architecture-and-technology/realsense-overview.html},
 note={(Date last accessed 21-Jun-2016)},
 }

@electronic{Lytro, 
 title={Lytro},
 url={https://lytro.com/},
 note={(Date last accessed 21-Jun-2016)},
 }

@electronic{Kinect2, 
 title={Kinect 2},
 url={https://developer.microsoft.com/en-us/windows/kinect/develop},
 note={(Date last accessed 21-Jun-2016)},
 }

@electronic{vuzix,
 title={Vuzix},
 url={https://www.vuzix.com/Products/m100-smart-glasses},
 note={(Date last accessed 23-Jun-2016)}
}

@inproceedings{aasted2011,
  title={Autonomous Mechanical Thinning Using Scanning LIDAR},
  author={Aasted, Matthew M and Dise, Reuben J and Baugher, Tara A and Schupp, James R and Heinemann, Paul H and Singh, Sanjiv},
  booktitle={2011 Louisville, Kentucky, August 7-10, 2011},
  pages={1},
  year={2011},
  organization={American Society of Agricultural and Biological Engineers}
}

@Misc{OpenCV,
 author = {OpenCV},
 howpublished = {\url{http://opencv.org/}},
 url = http://opencv.org/
}

@Misc{NeoVision2,
author = {Neovision2},
howpublished = {\url{http://ilab.usc.edu/neo2/dataset/tower/training/}},
url = http://ilab.usc.edu/neo2/dataset/tower/training/
}

@electronic{CNNGPUSpecs,
 title={{NVIDIA}},
 url={http://www.nvidia.com/docs/IO/43395/BD-05238-001_v03.pdf},
 note={(Date last accessed 30-May-2016)}
}

@electronic{hmin,
title = {{Jim Mutch}},
url = {http://cbcl.mit.edu/jmutch/hmin/},
note={{Date last accessed 30-May-2016}}
}


@inproceedings{Dalal2005,
 author = {Dalal, Navneet and Triggs, Bill},
 title = {{Histograms of Oriented Gradients for Human Detection}},
 booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
 year = {2005},
 isbn = {0-7695-2372-2}
} 

@inproceedings{DalalThesis2006,
 author = {Dalal, Navneet},
 title = {{Finding People in Images and Videos}},
 booktitle = {Ph.D. Thesis},
 year = {2006},
} 

@INPROCEEDINGS{Google2013,
author={Dean, T. and Ruzon, M.A. and Segal, M. and Shlens, J. and Vijayanarasimhan, S. and Yagnik, J.},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
title={{Fast, Accurate Detection of 100,000 Object Classes on a Single Machine}},
year={2013},
month={June},
}

@Article{Everingham2010,
   author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
   title = "The Pascal Visual Object Classes (VOC) Challenge",
   journal = "International Journal of Computer Vision",
   volume = "88",
   year = "2010",
   number = "2",
   month = jun,
   pages = "303--338",
} 

@INPROCEEDINGS{ImageNet,
author={J. Deng and others},
booktitle={Computer Vision and Pattern Recognition, IEEE Conference on},
title={{ImageNet: A large-scale hierarchical image database}},
year={2009},
month={June},
pages={248-255},
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
pages={1-42},
month={April}
}

@article{UoCTTI,
 author = {Felzenszwalb, Pedro F. and Girshick, Ross B. and McAllester, David and Ramanan, Deva},
 title = {{Object Detection with Discriminatively Trained Part-Based Models}},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {September 2010},
 year = {2010},
 issn = {0162-8828},
 keywords = {Object recognition, Object recognition, deformable models, pictorial structures, discriminative training, latent SVM., deformable models, discriminative training, latent SVM., pictorial structures},
} 

@article{Lowe2004,
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Lowe\_Distinctive Image Features from Scale-Invariant Keypoints\_2004.pdf:pdf},
issn = {0920-5691},
journal = {IJCV},
month = nov,
number = {2},
pages = {91--110},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
volume = {60},
year = {2004}
}

@INPROCEEDINGS{Malisiewicz2011, 
author={Malisiewicz, T. and Gupta, A and Efros, AA}, 
booktitle={IEEE International Conference on Computer Vision}, 
title={{Ensemble of exemplar-SVMs for object detection and beyond}}, 
year={2011}, 
month={Nov}, 
}

@ARTICLE{Dollar2012, 
author={Dollar, P. and Wojek, C. and Schiele, B. and Perona, P.}, 
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
title={{Pedestrian Detection: An Evaluation of the State of the Art}}, 
year={2012}, 
month={April}, 
}

@article{Benoit2010,
author = {Benoit, A. and Caplier, A. and Durette, B. and Herault, J.},
doi = {10.1016/j.cviu.2010.01.011},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Benoit et al.\_Using Human Visual System modeling for bio-inspired low level image processing\_2010.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = jul,
number = {7},
pages = {758--773},
publisher = {Elsevier Inc.},
title = {{Using Human Visual System modeling for bio-inspired low level image processing}},
volume = {114},
year = {2010}
}

@article{Karam2011,
author = {Karam, L. and Sadaka, N. and Ferzli, R and Ivanovski, Z},
doi = {10.1109/TIP.2011.2159324},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Karam et al.\_An efficient selective perceptual-based super-resolution estimator.\_2011.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on image processing},
month = dec,
number = {12},
pages = {3470--82},
pmid = {21672677},
title = {{An efficient selective perceptual-based super-resolution estimator.}},
volume = {20},
year = {2011}
}

@article{Giachetti1998,
author = {Giachetti, A. and Campani, M. and Torre, V.},
doi = {10.1109/70.660838},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Giachetti, Campani, Torre\_The use of optical flow for road navigation\_1998.pdf:pdf},
issn = {1042296X},
journal = {IEEE Transi. on Robotics and Automation},
number = {1},
pages = {34--48},
title = {{The use of optical flow for road navigation}},
volume = {14},
year = {1998}
}

@article{Hou2011,
author = {Hou, X. and Harel, J. and Koch, C.},
doi = {10.1109/TPAMI.2011.146},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Hou, Harel, Koch\_Image Signature Highlighting Sparse Salient Regions.\_2011.pdf:pdf},
issn = {1939-3539},
journal = {PAMI},
month = jul,
title = {{Image Signature: Highlighting Sparse Salient Regions.}},
year = {2011}
}

@article{Lang2012,
author = {Lang, Congyan and Liu, Guangcan and Yu, Jian and Yan, Shuicheng},
doi = {10.1109/TIP.2011.2169274},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Saliency Detection by Multitask Sparsity Pursuit.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on Image Processing},
title = {{Saliency Detection by Multitask Sparsity Pursuit}},
year = {2012}
}

@article{Collins,
author = {Collins, R.},
doi = {10.1109/CVPR.2003.1211475},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Collins\_Mean-shift blob tracking through scale space\_Unknown.pdf:pdf},
isbn = {0-7695-1900-8},
journal = {CVPR},
title = {{Mean-shift blob tracking through scale space}},
}

@article{Judd2011,
author = {Judd, T. and Durand, F. and Torralba, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd Fixations on Low Res Images Poster.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
pmid = {21518823},
title = {{Fixations on Low-Resolution Images.}},
year = {2011}
}

@inproceedings{Delaluz2002,
author = {Delaluz, V. and Sivasubramaniam, A. and Kandemir, M. and Vijaykrishnan, N. and Irwin, M.J.},
booktitle = {DAC},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DRAM\_dac02.pdf:pdf},
isbn = {1-58113-461-4},
keywords = {dram,energy management,operating systems,scheduler},
title = {{Scheduler-based DRAM energy management}},
year = {2002}
}

@article{Xu2010,
author = {Xu, J. and Yang, Z. and Tsien, J.},
doi = {10.1371/journal.pone.0015796},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Emergence of Visual Saliency from Natural Scenes via Context-Mediated Probability Distributions Coding.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
mendeley-tags = {Saliency},
number = {12},
title = {{Emergence of visual saliency from natural scenes via context-mediated probability distributions coding.}},
year = {2010}
}

@inproceedings{Mishra2009,
author = {Mishra, A. and Aloimonos, Y.},
booktitle = {ICCV},
doi = {10.1109/ICCV.2009.5459254},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/iccv2009\_activeSeg.pdf:pdf},
isbn = {978-1-4244-4420-5},
keywords = {fixation},
mendeley-tags = {fixation},
title = {{Active segmentation with fixation}},
year = {2009}
}

@article{Wolfe2004,
author = {Wolfe, J. and Horowitz, T.},
doi = {10.1038/nrn1411},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/WhatAttributesGuidetheDeploymentofSaliency.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
mendeley-tags = {Saliency},
pmid = {15152199},
title = {{What attributes guide the deployment of visual attention and how do they do it?}},
year = {2004}
}

@article{Daugman1985,
author = {Daugman, J.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Daugman Uncertainty.pdf:pdf},
journal = {Journal of the Optical Society of America},
title = {{Uncertainty Relation for Resolution in Space, Spatial Frequency, and Orientation Optimized by Two-Dimensional Visual Cortical Filters}},
year = {1985}
}

@inproceedings{Park2012,
author = {Park, S. and others},
booktitle = {ASPDAC},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/A reconfigurable platform for the design and verification of domain-specific accelerators.pdf:pdf},
isbn = {9781467307727},
title = {{A Reconfigurable Platform for the Design and Verification of Domain-Specific Accelerators}},
year = {2012}
}

@article{Burgsteiner2006,
author = {Burgsteiner, H. and others},
doi = {10.1007/s10489-006-0007-1},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Burgsteiner et al.\_Movement prediction from real-world images using a liquid state machine\_2006.pdf:pdf},
issn = {0924-669X},
journal = {Applied Intelligence},
title = {{Movement prediction from real-world images using a liquid state machine}},
year = {2006}
}

@inproceedings{Kestur2011,
author = {Kestur, S. and Dantara, D. and Narayanan, V.},
booktitle = {Design, Automation, and Test in Europe},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/MDL\_SHARC- A streaming model for FPGA accelerators and its application to Saliency.pdf:pdf},
isbn = {9783981080179},
keywords = {FPGA,Saliency},
mendeley-tags = {FPGA,Saliency},
title = {{SHARC : A Streaming Model for FPGA Accelerators and its Application to Saliency}},
year = {2011}
}

@inproceedings{Liu2011,
author = {Liu, S. and {Pattabiraman K.} and Moscibroda, T. and Zorn, B. },
booktitle = {ASLPOS},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Flikker.pdf:pdf},
isbn = {9781450302661},
keywords = {critical,dram refresh,power-savings,soft errors},
title = {{Flikker: Saving DRAM Refresh-power through Critical Data Partitioning}},
year = {2011}
}

@article{Rosenfeld2011,
author = {Rosenfeld, P and Cooper-Balis, E and Jacob, B},
doi = {10.1109/L-CA.2011.4},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DRAMSim2.pdf:pdf},
issn = {1556-6056},
journal = {IEEE Computer Architecture Letters},
month = jan,
number = {1},
pages = {16--19},
title = {{DRAMSim2: A Cycle Accurate Memory System Simulator}},
volume = {10},
year = {2011}
}

@article{Tatler2011,
author = {Tatler, Benjamin W and Hayhoe, Mary M and Land, Michael F and Ballard, Dana H},
doi = {10.1167/11.5.5.Introduction},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Tatler et al.\_Eye guidance in natural vision Reinterpreting salience\_2011.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,11,1167,2011,23,5,Saliency,b,ballard,citation,content,d,doi,eye guidance in natural,eye movements,f,h,hayhoe,http,journal of vision,journalofvision,land,learning,m,natural tasks,org,prediction,reinterpreting,reward,salience,tatler,vision,w,www},
mendeley-tags = {Saliency},
pages = {1--23},
title = {{Eye Guidance in Natural Vision : Reinterpreting Salience}},
volume = {11},
year = {2011}
}

@article{Kuchnio2011,
author = {Kuchnio, Peter and Capson, David},
doi = {10.1109/CRV.2011.22},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kuchnio, Capson\_GPU-Accelerated Foveation for Video Frame Rate Tracking\_2011.pdf:pdf},
isbn = {978-1-61284-430-5},
journal = {2011 Canadian Conference on Computer and Robot Vision},
keywords = {-gpu,algorithm in cuda are,cuda,details of,discussed in section iii,foveation,image-based visual servo,mapping of a foveated,motion segmentation,optical flow,scription of the parallel},
month = may,
pages = {117--124},
publisher = {Ieee},
title = {{GPU-Accelerated Foveation for Video Frame Rate Tracking}},
year = {2011}
}

@book{Land2009,
author = {Land, Michael F and Tatler, Benjamin W},
booktitle = {Psychology Press},
keywords = {Micheal F. Land and Benjamin W. Tatler,Vision},
mendeley-tags = {Vision},
publisher = {Oxford},
title = {{Looking and Acting: Vision and eye movements in natural behaviour}},
year = {2009}
}

@inproceedings{Farhadi2010,
author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
booktitle = {European Conference on Computer Vision},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/sentence.pdf:pdf},
keywords = {scene},
mendeley-tags = {scene},
title = {{Every Picture Tells a Story : Generating Sentences from Images}},
year = {2010}
}

@article{Wal1992,
author = {Wal, Gooitzen S. and Burt, Peter J.},
doi = {10.1007/BF00055150},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Wal, Burt\_A VLSI pyramid chip for multiresolution image analysis\_1992.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = sep,
number = {3},
pages = {177--189},
title = {{A VLSI pyramid chip for multiresolution image analysis}},
volume = {8},
year = {1992}
}

@article{Judd2009,
author = {Judd, Tilke and Ehinger, Krista and Durand, Fredo and Torralba, Antonio},
doi = {10.1109/ICCV.2009.5459462},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd Learning to Predict Where Humans Look Poster.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {2106--2113},
publisher = {Ieee},
title = {{Learning to Predict Where Humans Look}},
year = {2009}
}

@techreport{Mutch2010,
address = {Cambridge, MA},
author = {Mutch, Jim and Knoblich, Ulf and Poggio, Tomaso},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/MIT-CSAIL-TR-2010-013.pdf:pdf},
keywords = {GPU},
mendeley-tags = {GPU},
title = {{CNS : a GPU-based framework for simulating cortically-organized networks}},
year = {2010}
}

@inproceedings{Judd2009a,
author = {Judd, Tilke and Ehinger, Krista and Torralba, Antonio},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Juddwherepeoplelook.pdf:pdf},
keywords = {Saliency},
mendeley-tags = {Saliency},
pages = {2106--2113},
title = {{Learning to Predict Where Humans Look}},
year = {2009}
}

@article{Mutch2008,
author = {Mutch, Jim and Lowe, David G.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/ijcv2008\_mutch\_lowe.pdf:pdf},
journal = {IJCV},
keywords = {object},
mendeley-tags = {object},
title = {{Object class recognition and localization using sparse features with limited receptive fields}},
year = {2008}
}

@article{Jiang2012,
author = {Jiang, Zhuolin and Lin, Zhe and Davis, Larry S.},
doi = {10.1016/j.cviu.2012.02.004},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Jiang, Lin, Davis\_Class consistent k-means Application to face and action recognition\_2012.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = jun,
number = {6},
pages = {730--741},
publisher = {Elsevier Inc.},
title = {{Class consistent k-means: Application to face and action recognition}},
volume = {116},
year = {2012}
}

@article{Wolfe2002,
author = {Wolfe, Jeremy M},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Wolfe\_Visual Search\_2002.pdf:pdf},
pages = {1--41},
title = {{Visual Search}},
year = {2002}
}

@inproceedings{Liu2012,
author = {Liu, J. and Jaiyen, B. and Veras, R and Mutlu, O.},
booktitle = {ISCA},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/RAIDR.pdf:pdf},
isbn = {9781467304764},
keywords = {dram},
mendeley-tags = {dram},
title = {{RAIDR: Retention-Aware Intelligent DRAM Refresh}},
year = {2012}
}

@article{Parkhurst2002,
abstract = {A biologically motivated computational model of bottom-up visual selective attention was used to examine the degree to which stimulus salience guides the allocation of attention. Human eye movements were recorded while participants viewed a series of digitized images of complex natural and artificial scenes. Stimulus dependence of attention, as measured by the correlation between computed stimulus salience and fixation locations, was found to be significantly greater than that expected by chance alone and furthermore was greatest for eye movements that immediately follow stimulus onset. The ability to guide attention of three modeled stimulus features (color, intensity and orientation) was examined and found to vary with image type. Additionally, the effect of the drop in visual sensitivity as a function of eccentricity on stimulus salience was examined, modeled, and shown to be an important determiner of attentional allocation. Overall, the results indicate that stimulus-driven, bottom-up mechanisms contribute significantly to attentional guidance under natural viewing conditions.},
author = {Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Modeling the role of salience in the allocation of overt visual attention.pdf:pdf},
issn = {0042-6989},
journal = {Vision Research},
keywords = {Analysis of Variance,Attention,Attention: physiology,Biological,Computer Simulation,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Models,Normal Distribution,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {107--23},
pmid = {11804636},
title = {{Modeling the Role of Salience in the Allocation of Overt Visual Attention}},
volume = {42},
year = {2002}
}

@article{Bandera1989,
author = {Bandera, C. and Scott, P.D.},
doi = {10.1109/ICSMC.1989.71367},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bandera, Scott\_Foveal machine vision systems\_1989.pdf:pdf},
journal = {Conference Proceedings., IEEE International Conference on Systems, Man and Cybernetics},
keywords = {Foveation},
mendeley-tags = {Foveation},
pages = {596--599},
publisher = {Ieee},
title = {{Foveal machine vision systems}},
year = {1989}
}

@article{Geisler1998,
author = {Geisler, Wilson S and Perry, Jeffrey S},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/ARealTimeFoveatedMRSystemforLowBWVideoCommunication.pdf:pdf},
journal = {Proceedings of the SPIE: The International Society for Optical Engineering},
keywords = {Foveation,eye tracking,foveated imaging,foveation,human,motion compensation,multiresolution pyramid,video,video compression,vision,zero-tree coding},
mendeley-tags = {Foveation},
title = {{A Real-Time Foveated Multiresolution System for Low-Bandwidth Video Communication}},
volume = {3299},
year = {1998}
}

@article{Deng2009,
author = {Deng, L. and Chakrabarti, C. and Pitsianis, N. and Sun, X.},
doi = {10.1117/12.834184},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Deng et al.\_Automated optimization of look-up table implementation for function evaluation on FPGAs\_2009.pdf:pdf},
journal = {Proceedings of SPIE},
keywords = {automatic generation,fpgas,function evaluation,look-up table,resource minimization},
pages = {744413--744413--9},
publisher = {Spie},
title = {{Automated optimization of look-up table implementation for function evaluation on FPGAs}},
year = {2009}
}

@article{Young1998,
abstract = {This paper presents a method for detecting and classifying a target from its foveal (graded resolution) imagery using a multiresolution neural network. Target identification decisions are based on minimizing an energy function. This energy function is evaluated by comparing a candidate blob with a library of target models at several levels of resolution simultaneously available in the current foveal image. For this purpose, a concurrent (top-down-and-bottom-up) matching procedure is implemented via a novel multilayer Hopfield neural network. The associated energy function supports not only interactions between cells at the same resolution level, but also between sets of nodes at distinct resolution levels. This permits features at different resolution levels to corroborate or refute one another contributing to an efficient evaluation of potential matches. Gaze control, refoveation to more salient regions of the available image space, is implemented as a search for high resolution features which will disambiguate the candidate blob. Tests using real two-dimensional (2-D) objects and their simulated foveal imagery are provided.},
author = {Young, S S and Scott, P D and Bandera, C},
doi = {10.1109/83.704306},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Young, Scott, Bandera\_Foveal automatic target recognition using a multiresolution neural network.\_1998.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = jan,
number = {8},
pages = {1122--35},
pmid = {18276329},
title = {{Foveal automatic target recognition using a multiresolution neural network.}},
volume = {7},
year = {1998}
}

@article{Hrabar2005,
author = {Hrabar, S. and Sukhatme, G.S. and Corke, P. and Usher, K. and Roberts, J.},
doi = {10.1109/IROS.2005.1544998},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Hrabar et al.\_Combined optic-flow and stereo-based navigation of urban canyons for a UAV\_2005.pdf:pdf},
isbn = {0-7803-8912-3},
journal = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {3309--3316},
publisher = {Ieee},
title = {{Combined optic-flow and stereo-based navigation of urban canyons for a UAV}},
year = {2005}
}

@article{Riche2012,
author = {Riche, Nicolas and Mancas, Matei and Culibrk, Dubravko and Crnojevic, Vladimir and Gosselin, Bernard and Dutoit, Thierry},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Dynamic saliency models and human attention- a comparative study on videos.pdf:pdf},
journal = {Proceedings of the 11th Asian Conference on Computer Vision (ACCV)},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{Dynamic saliency models and human attention : a comparative study on videos}},
year = {2012}
}

@article{Itti2001,
abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
author = {Itti, L and Koch, C},
doi = {10.1038/35058500},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Itti\_Koch\_ComputationalModellingVisualAttention.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: metabolism,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
pmid = {11256080},
title = {{Computational Modelling of Visual Attention}},
year = {2001}
}

@article{Thevenaz2000,
abstract = {Based on the theory of approximation, this paper presents a unified analysis of interpolation and resampling techniques. An important issue is the choice of adequate basis functions. We show that, contrary to the common belief, those that perform best are not interpolating. By opposition to traditional interpolation, we call their use generalized interpolation; they involve a prefiltering step when correctly applied. We explain why the approximation order inherent in any basis function is important to limit interpolation artifacts. The decomposition theorem states that any basis function endowed with approximation order can be expressed as the convolution of a B-spline of the same order with another function that has none. This motivates the use of splines and spline-based functions as a tunable way to keep artifacts in check without any significant cost penalty. We discuss implementation and performance issues, and we provide experimental evidence to support our claims.},
author = {Th\'{e}venaz, P and Blu, T and Unser, M},
doi = {10.1109/42.875199},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Th\'{e}venaz, Blu, Unser\_Interpolation revisited.\_2000.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
keywords = {Artifacts,Costs and Cost Analysis,Diagnostic Imaging,Diagnostic Imaging: economics,Diagnostic Imaging: methods,Fourier Analysis,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Mathematics},
month = jul,
number = {7},
pages = {739--58},
pmid = {11055789},
title = {{Interpolation revisited.}},
volume = {19},
year = {2000}
}

@article{Bolduc1998,
author = {Bolduc, Marc and Levine, Martin D.},
doi = {10.1006/cviu.1997.0560},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bolduc, Levine\_A Review of Biologically Motivated Space-Variant Data Reduction Models for Robotic Vision\_1998.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = feb,
number = {2},
pages = {170--184},
title = {{A Review of Biologically Motivated Space-Variant Data Reduction Models for Robotic Vision}},
volume = {69},
year = {1998}
}

@article{Vijayakumar2001,
author = {Vijayakumar, S. and Conradt, J. and Shibata, T. and Schaal, S.},
doi = {10.1109/IROS.2001.976418},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Vijayakumar et al.\_Overt visual attention for a humanoid robot\_2001.pdf:pdf},
isbn = {0-7803-6612-3},
journal = {Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180)},
number = {Iros},
pages = {2332--2337},
publisher = {Ieee},
title = {{Overt visual attention for a humanoid robot}},
volume = {4},
year = {2001}
}

@article{Land2000,
abstract = {In cricket, a batsman watches a fast bowler's ball come toward him at a high and unpredictable speed, bouncing off ground of uncertain hardness. Although he views the trajectory for little more than half a second, he can accurately judge where and when the ball will reach him. Batsmen's eye movements monitor the moment when the ball is released, make a predictive saccade to the place where they expect it to hit the ground, wait for it to bounce, and follow its trajectory for 100-200 ms after the bounce. We show how information provided by these fixations may allow precise prediction of the ball's timing and placement. Comparing players with different skill levels, we found that a short latency for the first saccade distinguished good from poor batsmen, and that a cricket player's eye movement strategy contributes to his skill in the game.},
author = {Land, M F and McLeod, P},
doi = {10.1038/81887},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/From eye movements to actions- how batsmen hit the ball.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Adult,Baseball,Baseball: physiology,Head Movements,Head Movements: physiology,Humans,Male,Motion Perception,Motion Perception: physiology,Motor Skills,Motor Skills: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Pursuit,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Smooth,Smooth: physiology,Sports,Sports: physiology,Vision},
mendeley-tags = {Vision},
month = dec,
number = {12},
pages = {1340--5},
pmid = {11100157},
title = {{From eye movements to actions: how batsmen hit the ball.}},
volume = {3},
year = {2000}
}

@article{Lehmann1999,
author = {Lehmann, T M and G\"{o}nner, C and Spitzer, K},
doi = {10.1109/42.816070},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
keywords = {Diagnostic Imaging,Fourier Analysis,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods},
month = nov,
number = {11},
pages = {1049--75},
pmid = {10661324},
title = {{Survey: interpolation methods in medical image processing.}},
volume = {18},
year = {1999}
}

@article{ISVLSI2013,
author = {Sungho Park and Ahmed Al Maashri and Yang Xiao and Kevin M. Irick and Vijaykrishnan Narayanan},
title = {Saliency-driven dynamic configuration of HMAX for energy-efficient multi-object recognition},
journal ={2014 IEEE Computer Society Annual Symposium on VLSI},
volume = {0},
issn = {2159-3469},
pages = {139-144},
year = {2013},
}

@article{Einhauser2003,
author = {Einhauser, Wolfgang and Konig, Peter},
doi = {10.1046/j.1460-9568.2003.02508.x},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Einhauser, Konig\_Does luminance-contrast contribute to a saliency map for overt visual attention\_2003.pdf:pdf},
issn = {0953-816X},
journal = {European Journal of Neuroscience},
keywords = {eye movements,hierarchy,human,top-down,visual system},
month = mar,
number = {5},
pages = {1089--1097},
title = {{Does luminance-contrast contribute to a saliency map for overt visual attention?}},
volume = {17},
year = {2003}
}

@inproceedings{Liu2013,
author = {Liu, Jamie and Jaiyen, Ben and Kim, Yoongu and Wilkerson, Chris},
booktitle = {International Symposium on Computer Architecture},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/dram-retention\_isca13.pdf:pdf},
isbn = {9781450320795},
title = {{An Experimental Study of Data Retention Behavior in Modern DRAM Devices : Implications for Retention Time Profiling Mechanisms}},
year = {2013}
}

@article{Karam2012,
author = {Karam, Samuel F . Dodge and Lina J .},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/gesture\_ICIP2012\_cameraready\_final.pdf:pdf},
journal = {International Conference on Image Processing},
title = {{Attentive gesture recognition}},
year = {2012}
}

@article{DeBole2011,
author = {DeBole, M. and Maashri, a. Al and Cotter, M. and Yu, C-L. and Chakrabarti, C. and Narayanan, V.},
doi = {10.1109/ICCAD.2011.6105351},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/DeBole et al.\_A framework for accelerating neuromorphic-vision algorithms on FPGAs\_2011.pdf:pdf},
isbn = {978-1-4577-1400-9},
journal = {2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
keywords = {- multi-fpga partitioning,fpga application mapping,fpga programming,neuromorphic vision algorithms},
month = nov,
pages = {810--813},
publisher = {Ieee},
title = {{A framework for accelerating neuromorphic-vision algorithms on FPGAs}},
year = {2011}
}

@article{Jablin2009,
author = {Jablin, Thomas and Upton, Dan and August, David and Hazelwood, Kim and Mahlke, Scott},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/multicore compilation strategies and challenges.pdf:pdf},
journal = {IEEE Signal Processing Magazine},
keywords = {Compiler},
mendeley-tags = {Compiler},
number = {November},
pages = {55--63},
title = {{Multicore Compilation Strategies and Challenges [}},
year = {2009}
}

@article{Bruce2006,
author = {Bruce, Neil D B and Tsotsos, John K},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bruce\_Saliency Based on Information Maximization.pdf\_Unknown.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {155--162},
title = {{Saliency Based on Information Maximization}},
volume = {18},
year = {2006}
}

@techreport{Judd2012,
author = {Judd, T. and Durand, F. and Torralba, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Judd, Durand, Torralba\_A Benchmark of Computational Models of Saliency to Predict Human Fixations A Benchmark of Computational Models of Saliency to Predict Human Fixations\_2012.pdf:pdf},
institution = {Massachusetts Institute of Technology},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{A Benchmark of Computational Models of Saliency to Predict Human Fixations}},
year = {2012}
}

@inproceedings{Nere2011,
author = {Nere, A. and Hashmi, A. and Lipasti, M.},
booktitle = {IPDPS},
doi = {10.1109/IPDPS.2011.88},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/nere\_ipdps\_2011.pdf:pdf},
isbn = {978-1-61284-372-8},
keywords = {-cortical learning algorithms,gpgpu,profiling},
title = {{Profiling Heterogeneous Multi-GPU Systems to Accelerate Cortically Inspired Learning Algorithms}},
year = {2011}
}

@article{Grzyb2009,
author = {Grzyb, B. and Chinellato, E. and Wojcik, G. and Kaminski, W.},
doi = {10.1109/IJCNN.2009.5179025},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Grzyb et al.\_Facial expression recognition based on Liquid State Machines built of alternative neuron models\_2009.pdf:pdf},
isbn = {978-1-4244-3548-7},
journal = {2009 Int. Joint Conf. on Neural Networks},
title = {{Facial expression recognition based on Liquid State Machines built of alternative neuron models}},
year = {2009}
}

@article{Burt1983,
author = {Burt, P. and Adelson, E.},
doi = {10.1145/245.247},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Burt, Adelson\_A multiresolution spline with application to image mosaics\_1983.pdf:pdf},
issn = {07300301},
journal = {ACM Trans. on Graphics},
title = {{A multiresolution spline with application to image mosaics}},
year = {1983}
}

@article{Verstraeten2005,
author = {Verstraeten, D. and Schrauwen, B. and Stroobandt, D. and {Van Campenhout}, J.},
doi = {10.1016/j.ipl.2005.05.019},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Verstraeten et al.\_Isolated word recognition with the Liquid State Machine a case study\_2005.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {liquid state machine,parallel processing,speech recognition,spiking neural networks},
month = sep,
number = {6},
pages = {521--528},
title = {{Isolated word recognition with the Liquid State Machine: a case study}},
volume = {95},
year = {2005}
}

@article{Chen2006,
author = {Chen, G. and Xue, L. and Kim, J. and Sobti, K. and Deng, L. and Sun, X. and Pitsianis, N. and Chakrabarti, C. and Kandemir, M. and Vijaykrishnan, N.},
doi = {10.1109/SOCC.2006.283861},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Chen et al.\_Geometric Tiling for Reducing Power Consumption in Structured Matrix Operations\_2006.pdf:pdf},
isbn = {0-7803-9782-7},
journal = {2006 IEEE International SOC Conference},
month = sep,
pages = {113--114},
publisher = {Ieee},
title = {{Geometric Tiling for Reducing Power Consumption in Structured Matrix Operations}},
year = {2006}
}

@inproceedings{Venkatesh2011,
author = {Venkatesh, Ganesh and Sampson, Jack and Goulding-hotta, Nathan and Venkata, Sravanthi Kota and Taylor, Michael Bedford and Swanson, Steven},
booktitle = {IEEE Micro},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Micro2011QASICS.pdf:pdf},
isbn = {9781450310536},
keywords = {Dark Silicon,conservation core,dark silicon,heterogeneous many-core,merging,q s c ore,specialization,utilization,wall},
mendeley-tags = {Dark Silicon},
title = {{QSCORES : Trading Dark Silicon for Scalable Energy Efficiency with Quasi-Specific Cores}},
year = {2011}
}

@article{Walther2006,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Walther, Koch\_Modeling attention to salient proto-objects.\_2006.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Attention,Biological,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models,Neural Networks (Computer),Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,ROC Curve,Visual,Visual: physiology},
month = nov,
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling Attention to Salient Proto-objects}},
volume = {19},
year = {2006}
}

@article{Vo2008,
author = {V\~{o}, Melissa L and Schneider, Werner X and Matthias, Ellen},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/vo\_2008\_jemr.pdf:pdf},
journal = {Journal of Eye Movement Research},
keywords = {Vision,processing efficiency,scene perception,theory of visual attention,transsaccadic memory,tva},
mendeley-tags = {Vision},
number = {2},
pages = {1--13},
title = {{Transsaccadic Scene Memory Revisited : A ' Theory of Visual Attention ( TVA )' Based Approach to Recognition Memory and Confidence for Objects in Naturalistic Scenes .}},
volume = {2},
year = {2008}
}

@article{Hu2014,
abstract = {About ten years ago, HMAX was proposed as a simple and biologically feasible model for object recognition, based on how the visual cortex processes information. However, the model does not encompass sparse firing, which is a hallmark of neurons at all stages of the visual pathway. The current paper presents an improved model, called sparse HMAX, which integrates sparse firing. This model is able to learn higher-level features of objects on unlabeled training images. Unlike most other deep learning models that explicitly address global structure of images in every layer, sparse HMAX addresses local to global structure gradually along the hierarchy by applying patch-based learning to the output of the previous layer. As a consequence, the learning method can be standard sparse coding (SSC) or independent component analysis (ICA), two techniques deeply rooted in neuroscience. What makes SSC and ICA applicable at higher levels is the introduction of linear higher-order statistical regularities by max pooling. After training, high-level units display sparse, invariant selectivity for particular individuals or for image categories like those observed in human inferior temporal cortex (ITC) and medial temporal lobe (MTL). Finally, on an image classification benchmark, sparse HMAX outperforms the original HMAX by a large margin, suggesting its great potential for computer vision.},
author = {Hu, Xiaolin and Zhang, Jianwei and Li, Jianmin and Zhang, Bo},
doi = {10.1371/journal.pone.0081813},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/SparseHMAX.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
month = jan,
number = {1},
pages = {e81813},
pmid = {24392078},
title = {{Sparsity-regularized HMAX for visual recognition.}},
volume = {9},
year = {2014}
}

@inproceedings{Nair2013,
author = {Nair, P. and Chou, C. and Qureshi, M.},
booktitle = {HPCA},
doi = {10.1109/HPCA.2013.6522355},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Refresh\_Pausing.pdf:pdf},
isbn = {978-1-4673-5587-2},
keywords = {refresh},
mendeley-tags = {refresh},
title = {{A case for Refresh Pausing in DRAM memory systems}},
year = {2013}
}

@article{Kunar2007,
abstract = {Contextual cuing experiments show that when displays are repeated, reaction times to find a target decrease over time even when observers are not aware of the repetition. It has been thought that the context of the display guides attention to the target. The authors tested this hypothesis by comparing the effects of guidance in a standard search task with the effects of contextual cuing. First, in standard search, an improvement in guidance causes search slopes (derived from Reaction Time x Set Size functions) to decrease. In contrast, the authors found that search slopes in contextual cuing did not become more efficient over time (Experiment 1). Second, when guidance was optimal (e.g., in easy feature search), they still found a small but reliable contextual cuing effect (Experiments 2a and 2b), suggesting that other factors, such as response selection, contribute to the effect. Experiment 3 supported this hypothesis by showing that the contextual cuing effect disappeared when the authors added interference to the response selection process. Overall, the data suggest that the relationship between guidance and contextual cuing is weak and that response selection can account for part of the effect.},
author = {Kunar, Melina a and Flusberg, Stephen and Horowitz, Todd S and Wolfe, Jeremy M},
doi = {10.1037/0096-1523.33.4.816},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kunar et al.\_Does contextual cuing guide the deployment of attention\_2007.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adolescent,Adult,Attention,Cues,Female,Humans,Male,Middle Aged,Reaction Time,Visual Perception},
month = aug,
number = {4},
pages = {816--28},
pmid = {17683230},
title = {{Does contextual cuing guide the deployment of attention?}},
volume = {33},
year = {2007}
}

@article{Crouzet2011,
abstract = {Research progress in machine vision has been very significant in recent years. Robust face detection and identification algorithms are already readily available to consumers, and modern computer vision algorithms for generic object recognition are now coping with the richness and complexity of natural visual scenes. Unlike early vision models of object recognition that emphasized the role of figure-ground segmentation and spatial information between parts, recent successful approaches are based on the computation of loose collections of image features without prior segmentation or any explicit encoding of spatial relations. While these models remain simplistic models of visual processing, they suggest that, in principle, bottom-up activation of a loose collection of image features could support the rapid recognition of natural object categories and provide an initial coarse visual representation before more complex visual routines and attentional mechanisms take place. Focusing on biologically plausible computational models of (bottom-up) pre-attentive visual recognition, we review some of the key visual features that have been described in the literature. We discuss the consistency of these feature-based representations with classical theories from visual psychology and test their ability to account for human performance on a rapid object categorization task.},
author = {Crouzet, S\'{e}bastien M and Serre, Thomas},
doi = {10.3389/fpsyg.2011.00326},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Serre\_What\_are\_the\_features\_underlying\_rapid\_object\_recognition.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {computational models,computer vision,feedforward,rapid visual object recognition,visual features},
month = jan,
number = {Nov},
pmid = {22110461},
title = {{What are the Visual Features Underlying Rapid Object Recognition?}},
volume = {2},
year = {2011}
}

@inproceedings{CarrollAaronHeiser2010,
author = {Carroll, A. and Heiser, G.},
booktitle = {Usenix Annual Technical Conference},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Carroll.pdf:pdf},
title = {{An Analysis of Power Consumption in a Smartphone}},
year = {2010}
}

@article{Rutishauser,
author = {Rutishauser, U. and Walther, D. and Koch, C. and Perona, P.},
doi = {10.1109/CVPR.2004.1315142},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Rutishauser et al.\_Is bottom-up attention useful for object recognition\_Unknown.pdf:pdf},
isbn = {0-7695-2158-4},
journal = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
pages = {37--44},
publisher = {Ieee},
title = {{Is bottom-up attention useful for object recognition?}},
volume = {2}
}

@inproceedings{Fergus2004,
author = {Fergus, R. and Perona, P.},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshop on Generative-Model Based Vision},
doi = {10.1109/CVPR.2004.383},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Learning generative visual models from few training examples- an incremental Bayesian approach tested on 101 object categories.pdf:pdf},
keywords = {Object},
mendeley-tags = {Object},
pages = {178--178},
publisher = {Ieee},
title = {{Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories}},
year = {2004}
}

@inproceedings{Lee2013,
author = {Lee, Donghyuk and Kim, Yoongu and Seshadri, Vivek and Liu, Jamie and Subramanian, Lavanya and Mutlu, Onur},
booktitle = {2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)},
doi = {10.1109/HPCA.2013.6522354},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Tiered-Latency DRAM- A Low Latency and Low Cost DRAM Architecture.pdf:pdf},
isbn = {978-1-4673-5587-2},
month = feb,
pages = {615--626},
publisher = {Ieee},
title = {{Tiered-latency DRAM: A low latency and low cost DRAM architecture}},
year = {2013}
}

@inproceedings{Kestur2012,
author = {Kestur, S and others},
booktitle = {Field-Programmable Custom Computing Machines (FCCM), 2012 IEEE 20th Annual International Symposium on},
title = {{Emulating Mammalian Vision on Reconfigurable Hardware}},
month={April},
pages={141-148}, 
year = {2012}
}

@article{Schomberg1995,
abstract = {The authors explore a computational method for reconstructing an n-dimensional signal f from a sampled version of its Fourier transform f;. The method involves a window function w; and proceeds in three steps. First, the convolution g;=w;*f; is computed numerically on a Cartesian grid, using the available samples of f;. Then, g=wf is computed via the inverse discrete Fourier transform, and finally f is obtained as g/w. Due to the smoothing effect of the convolution, evaluating w;*f; is much less error prone than merely interpolating f;. The method was originally devised for image reconstruction in radio astronomy, but is actually applicable to a broad range of reconstructive imaging methods, including magnetic resonance imaging and computed tomography. In particular, it provides a fast and accurate alternative to the filtered backprojection. The basic method has several variants with other applications, such as the equidistant resampling of arbitrarily sampled signals or the fast computation of the Radon (Hough) transform.},
author = {Schomberg, H and Timmer, J},
doi = {10.1109/42.414625},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schomberg, Timmer\_The gridding method for image reconstruction by Fourier transformation.\_1995.pdf:pdf},
issn = {0278-0062},
journal = {IEEE transactions on medical imaging},
month = jan,
number = {3},
pages = {596--607},
pmid = {18215864},
title = {{The gridding method for image reconstruction by Fourier transformation.}},
volume = {14},
year = {1995}
}

@article{Rajashekar2008,
abstract = {The ability to automatically detect visually interesting regions in images has many practical applications, especially in the design of active machine vision and automatic visual surveillance systems. Analysis of the statistics of image features at observers' gaze can provide insights into the mechanisms of fixation selection in humans. Using a foveated analysis framework, we studied the statistics of four low-level local image features: luminance, contrast, and bandpass outputs of both luminance and contrast, and discovered that image patches around human fixations had, on average, higher values of each of these features than image patches selected at random. Contrast-bandpass showed the greatest difference between human and random fixations, followed by luminance-bandpass, RMS contrast, and luminance. Using these measurements, we present a new algorithm that selects image regions as likely candidates for fixation. These regions are shown to correlate well with fixations recorded from human observers.},
author = {Rajashekar, U and van der Linde, I and Bovik, a C and Cormack, L K},
doi = {10.1109/TIP.2008.917218},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Rajashekar et al.\_GAFFE a gaze-attentive fixation finding engine.\_2008.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Trans. on Image Processing},
keywords = {Algorithms,Artificial Intelligence,Attention,Attention: physiology,Automated,Automated: methods,Biological,Biomimetics,Biomimetics: methods,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Fixation,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Models,Ocular,Ocular: physiology,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Visual,Visual: physiology},
month = apr,
number = {4},
pages = {564--73},
pmid = {18390364},
title = {{GAFFE: A Gaze-Attentive Fixation Finding Engine}},
volume = {17},
year = {2008}
}

@article{Gupta2007,
author = {Gupta, Abhinav and Davis, Larry S and Park, College},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/cvpr\_2007.pdf:pdf},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
keywords = {scene},
mendeley-tags = {scene},
number = {2},
title = {{Objects in Action : An Approach for Combining Action Understanding and Object Perception}},
year = {2007}
}

@article{Advani2013,
author = {Advani, Siddharth and Sustersic, John and Irick, Kevin and Narayanan, Vijaykrishnan},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Advani\_ICASSP\_2013\_Paper.pdf:pdf},
journal = {IEEE Proceedings of The 38th International Conference on Acoustics, Speech, and Signal Processing},
keywords = {Foveation,Saliency},
mendeley-tags = {Foveation,Saliency},
title = {{A Multi-Resolution Saliency Framework To Drive Foveation}},
year = {2013}
}

@article{Azzopardi2012,
abstract = {Simple cells in primary visual cortex are believed to extract local contour information from a visual scene. The 2D Gabor function (GF) model has gained particular popularity as a computational model of a simple cell. However, it short-cuts the LGN, it cannot reproduce a number of properties of real simple cells, and its effectiveness in contour detection tasks has never been compared with the effectiveness of alternative models. We propose a computational model that uses as afferent inputs the responses of model LGN cells with center-surround receptive fields (RFs) and we refer to it as a Combination of Receptive Fields (CORF) model. We use shifted gratings as test stimuli and simulated reverse correlation to explore the nature of the proposed model. We study its behavior regarding the effect of contrast on its response and orientation bandwidth as well as the effect of an orthogonal mask on the response to an optimally oriented stimulus. We also evaluate and compare the performances of the CORF and GF models regarding contour detection, using two public data sets of images of natural scenes with associated contour ground truths. The RF map of the proposed CORF model, determined with simulated reverse correlation, can be divided in elongated excitatory and inhibitory regions typical of simple cells. The modulated response to shifted gratings that this model shows is also characteristic of a simple cell. Furthermore, the CORF model exhibits cross orientation suppression, contrast invariant orientation tuning and response saturation. These properties are observed in real simple cells, but are not possessed by the GF model. The proposed CORF model outperforms the GF model in contour detection with high statistical confidence (RuG data set: p<10(-4), and Berkeley data set: p<10(-4)). The proposed CORF model is more realistic than the GF model and is more effective in contour detection, which is assumed to be the primary biological role of simple cells.},
author = {Azzopardi, George and Petkov, Nicolai},
doi = {10.1007/s00422-012-0486-6},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/A CORF Computational Model of a simple cell that relies on LGN input outperforms the Gabor function model.pdf:pdf},
issn = {1432-0770},
journal = {Biological Cybernetics},
keywords = {Models,Neurons,Neurons: cytology,Theoretical,Visual Cortex,Visual Cortex: cytology},
month = mar,
number = {3},
pages = {177--89},
pmid = {22526357},
title = {{A CORF Computational Model of a Simple Cell that Relies on LGN Input Outperforms the Gabor Function Model}},
volume = {106},
year = {2012}
}

@article{Torralba2003,
abstract = {In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image.},
author = {Torralba, Antonio and Oliva, Aude},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Torralba, Oliva\_Statistics of natural image categories.\_2003.pdf:pdf},
issn = {0954-898X},
journal = {Network (Bristol, England)},
keywords = {Nature,Photic Stimulation,Photic Stimulation: methods,Statistics as Topic},
month = aug,
number = {3},
pages = {391--412},
pmid = {12938764},
title = {{Statistics of natural image categories.}},
volume = {14},
year = {2003}
}

@article{Muller2006,
author = {M\"{u}ller, Hermann J. and Krummenacher, Joseph},
doi = {10.1080/13506280500527676},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/M\"{u}ller, Krummenacher\_Visual search and selective attention\_2006.pdf:pdf},
isbn = {1350628050},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {4-8},
pages = {389--410},
title = {{Visual search and selective attention}},
volume = {14},
year = {2006}
}

@article{Riesenhuber1999,
abstract = {Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function.},
author = {Riesenhuber, M and Poggio, T},
doi = {10.1038/14819},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Poggio\_Hierarchical\_models\_of\_object\_recognition\_in\_cortex.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Computer Simulation,Form Perception,Form Perception: physiology,Hierarchy,Macaca,Mental Recall,Mental Recall: physiology,Models,Neurological,Neurons,Neurons: physiology,Object,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology},
mendeley-tags = {Hierarchy,Object},
month = nov,
number = {11},
pages = {1019--25},
pmid = {10526343},
title = {{Hierarchical models of object recognition in cortex.}},
volume = {2},
year = {1999}
}

@article{Kunar2006,
abstract = {In visual search tasks, attention can be guided to a target item--appearing amidst distractors--on the basis of simple features (e.g., finding the red letter among green). Chun and Jiang's (1998) contextual cuing effect shows that reaction times (RTs) are also speeded if the spatial configuration of items in a scene is repeated over time. In the present studies, we ask whether global properties of the scene can speed search (e.g., if the display is mostly red, then the target is at location X). In Experiment 1A, the overall background color of the display predicted the target location, and the predictive color could appear 0, 400, or 800 msec in advance of the search array. Mean RTs were faster in predictive than in nonpredictive conditions. However, there was little improvement in search slopes. The global color cue did not improve search efficiency. Experiments 1B-1F replicated this effect using different predictive properties (e.g., background orientation-texture and stimulus color). The results showed a strong RT effect of predictive background, but (at best) only a weak improvement in search efficiency. A strong improvement in efficiency was found, however, when the informative background was presented 1,500 msec prior to the onset of the search stimuli and when observers were given explicit instructions to use the cue (Experiment 2).},
author = {Kunar, Melina a and Flusberg, Stephen J and Wolfe, Jeremy M},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Kunar, Flusberg, Wolfe\_Contextual cuing by global features.\_2006.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Color Perception,Cues,Female,Field Dependence-Independence,Humans,Judgment,Male,Middle Aged,Orientation,Reaction Time},
month = oct,
number = {7},
pages = {1204--16},
pmid = {17355043},
title = {{Contextual cuing by global features.}},
volume = {68},
year = {2006}
}

@article{Goodrich2012,
author = {Goodrich, Ben and Arel, Itamar},
doi = {10.1109/CVPRW.2012.6239177},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Goodrich, Arel\_Reinforcement learning based visual attention with application to face detection\_2012.pdf:pdf},
isbn = {978-1-4673-1612-5},
journal = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
month = jun,
pages = {19--24},
publisher = {Ieee},
title = {{Reinforcement learning based visual attention with application to face detection}},
year = {2012}
}

@article{Bae2011,
author = {Bae, Sungmin and Cho, Yong Cheol Peter and Park, Sungho and Irick, Kevin M. and Jin, Yongseok and Narayanan, Vijaykrishnan},
doi = {10.1109/FCCM.2011.41},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/MDL\_An FPGA implementation of Information Theoretic Visual-Saliency System and Its Optimization.pdf:pdf},
isbn = {978-1-61284-277-6},
journal = {2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines},
keywords = {FPGA,Saliency},
mendeley-tags = {FPGA,Saliency},
month = may,
pages = {41--48},
publisher = {Ieee},
title = {{An FPGA Implementation of Information Theoretic Visual-Saliency System and Its Optimization}},
year = {2011}
}

@article{Traver2008,
author = {Traver, V. Javier and Pla, Filiberto},
doi = {10.1016/j.imavis.2007.11.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Traver, Pla\_Log-polar mapping template design From task-level requirements to geometry parameters\_2008.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {design criteria,genetic algorithm,log-polar vision,receptive fields},
title = {{Log-polar mapping template design: From task-level requirements to geometry parameters}},
year = {2008}
}

@article{Ghodrati2012,
abstract = {Humans can effectively and swiftly recognize objects in complex natural scenes. This outstanding ability has motivated many computational object recognition models. Most of these models try to emulate the behavior of this remarkable system. The human visual system hierarchically recognizes objects in several processing stages. Along these stages a set of features with increasing complexity is extracted by different parts of visual system. Elementary features like bars and edges are processed in earlier levels of visual pathway and as far as one goes upper in this pathway more complex features will be spotted. It is an important interrogation in the field of visual processing to see which features of an object are selected and represented by the visual cortex. To address this issue, we extended a hierarchical model, which is motivated by biology, for different object recognition tasks. In this model, a set of object parts, named patches, extracted in the intermediate stages. These object parts are used for training procedure in the model and have an important role in object recognition. These patches are selected indiscriminately from different positions of an image and this can lead to the extraction of non-discriminating patches which eventually may reduce the performance. In the proposed model we used an evolutionary algorithm approach to select a set of informative patches. Our reported results indicate that these patches are more informative than usual random patches. We demonstrate the strength of the proposed model on a range of object recognition tasks. The proposed model outperforms the original model in diverse object recognition tasks. It can be seen from the experiments that selected features are generally particular parts of target images. Our results suggest that selected features which are parts of target objects provide an efficient set for robust object recognition.},
author = {Ghodrati, M. and Khaligh-Razavi, S. and Ebrahimpour, R. and Rajaei, K. and Pooyan, M.},
doi = {10.1371/journal.pone.0032357},
file = {:Users/siddharthadvani/Documents/MDL/ARL/Papers/Ghodrati\_BioinspiredFeatures.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Brain Mapping,Brain Mapping: methods,Computational Biology,Computational Biology: methods,Computer Simulation,Humans,Models, Statistical,Models, Theoretical,Normal Distribution,Pattern Recognition, Visual,Photic Stimulation,Photic Stimulation: methods,Recognition (Psychology),Vision, Ocular,Visual Pathways,Visual Perception},
title = {{How can selection of biologically inspired features improve the performance of a robust object recognition model?}},
year = {2012}
}

@article{Schrauwen,
abstract = {Hardware implementations of Spiking Neural Networks are numerous because they are well suited for implementation in digital and analog hardware, and outperform classic neural networks. This work presents an application driven digital hardware exploration where we implement real-time, isolated digit speech recognition using a Liquid State Machine. The Liquid State Machine is a recurrent neural network of spiking neurons where only the output layer is trained. First we test two existing hardware architectures which we improve and extend, but that appears to be too fast and thus area consuming for this application. Next, we present a scalable, serialized architecture that allows a very compact implementation of spiking neural networks that is still fast enough for real-time processing. All architectures support leaky integrate-and-fire membranes with exponential synaptic models. This work shows that there is actually a large hardware design space of Spiking Neural Network hardware that can be explored. Existing architectures have only spanned part of it.},
author = {Schrauwen, B. and D'Haene, M. and Verstraeten, D. and Van Campenhout, J.},
doi = {10.1016/j.neunet.2007.12.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schrauwen et al.\_Compact hardware liquid state machines on FPGA for real-time speech recognition.\_Unknown.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Action Potentials,Analog-Digital Conversion,Humans,Models, Neurological,Neural Networks (Computer),Recognition (Psychology),Signal Processing, Computer-Assisted,Speech,Time Factors},
title = {{Compact hardware liquid state machines on FPGA for real-time speech recognition.}},
}

@inproceedings{Chen2014,
author = {Chen, T. and Wang, J. and Chen, Y. and Temam, O.},
booktitle = {ASPLOS},
title = {{DianNao : A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning}},
year = {2014}
}

@phdthesis{Maashri2012,
author = {Maashri, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/maashri\_accelerated\_embedded\_vision\_systems\_v4.pdf:pdf},
title = {{Accelerating design and implementation of embedded vision systems}},
year = {2012}
}

@phdthesis{Dantara2011,
author = {Dantara, D.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Dharav\_Dantara\_MS\_Thesis.pdf:pdf},
keywords = {Accelerator},
mendeley-tags = {Accelerator},
school = {The Pennsylvania State University},
title = {{Reconfigurable Accelerators for Neuromorphic Systems}},
type = {MS Thesis},
year = {2011}
}

@phdthesis{Cotter2015,
author = {Cotter, M.},
title = {{Enabling Intelligent Vision Systems In A Configurable Multi-Algorithm Pipeline}},
booktitle = {Ph.D. Thesis},
year = {2015}
}

@inproceedings{Smith2015,
 author = {Smith, B.},
 title = {{Improving Object Recognition Performance Through Semantic Context Extraction}},
 booktitle = {MS Thesis},
 year = {2015},
} 

@inproceedings{Dharav2011,
 author = {Dantara, D.},
 title = {{Reconfigurable Accelerators for Neuromorphic Systems}},
 booktitle = {MS Thesis},
 year = {2011},
} 

@article{Shu-Ying2009,
author = {Shu-Ying, Y. and WeiMin, G. and Cheng, Z.},
doi = {10.1016/j.visres.2008.11.002},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Shu-Ying, WeiMin, Cheng\_Tracking unknown moving targets on omnidirectional vision.\_2009.pdf:pdf},
journal = {Vision research},
title = {{Tracking unknown moving targets on omnidirectional vision.}},
year = {2009}
}

@article{Lleras2004,
author = {Lleras, A. and {Von M\"{u}hlenen}, A.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Lleras, Von M\"{u}hlenen\_Spatial context and top-down strategies in visual search.\_2004.pdf:pdf},
issn = {0169-1015},
journal = {Spatial vision},
keywords = {Adult,Attention,Cues,Female,Humans,Individuality,Male,Random Allocation,Reaction Time,Space Perception},
title = {{Spatial context and top-down strategies in visual search.}},
year = {2004}
}

@article{Bruceb,
author = {Bruce, N.},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{An Information Theoretic Model of Saliency and Visual Search}},
}

@article{Belongie2002,
author = {Belongie, S. and Malik, J. and Puzicha, J.},
doi = {10.1109/34.993558},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Belongie, Malik, Puzicha\_Shape matching and object recognition using shape contexts\_2002.pdf:pdf},
issn = {01628828},
journal = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
month = apr,
number = {4},
pages = {509--522},
title = {{Shape matching and object recognition using shape contexts}},
volume = {5395},
year = {2009}
}

@misc{GodwinDwayne2012,
author = {{Godwin D.}, Cham J.},
booktitle = {Scientific American},
keywords = {brain},
mendeley-tags = {brain},
title = {{Your Brain by the Numbers}},
year = {2012}
}

@phdthesis{Kestur2012a,
author = {Kestur, S.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/1-SrinidhiKestur-Dissertation.pdf:pdf},
number = {May},
title = {{Domain-Specific Accelerators on Reconfigurable Platforms}},
year = {2012}
}

@inproceedings{Maashri2012a,
author = {Maashri, A. and others},
booktitle = {DAC},
keywords = {Object,domain-specific,power efficiency,recognition,system},
title = {{Accelerating Neuromorphic Vision Algorithms for Recognition}},
year = {2012}
}

@inproceedings{Clemons2012,
author = {Clemons, Jason and Zhu, Haishan and Savarese, Silvio and Austin, Todd and Arbor, Ann},
booktitle = {IEEE International Symposium on Workload Characterization},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/MEVBench.pdf:pdf},
title = {{MEVBench : A Mobile Computer Vision Benchmarking Suite}},
year = {2012}
}

@article{Bruce2009a,
author = {Bruce, N. and Tsotsos, J.},
doi = {10.1167/9.3.5},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Bruce, Tsotsos\_Saliency, attention, and visual search an information theoretic approach.\_2009.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
language = {en},
mendeley-tags = {Saliency},
title = {{Saliency, Attention, and Visual Search: An Information Theoretic Approach}},
year = {2009}
}

@article{Yamamoto1996,
author = {Yamamoto, H. and Yeshurun, Y. and Levine, M.},
doi = {10.1006/cviu.1996.0004},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Yamamoto, Yeshurun, Levine\_An Active Foveated Vision System Attentional Mechanisms and Scan Path Covergence Measures\_1996.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
title = {{An Active Foveated Vision System: Attentional Mechanisms and Scan Path Covergence Measures}},
year = {1996}
}

@book{Gonzalez2007,
author = {Gonzalez, R. and Woods, R.},
isbn = {013168728X},
keywords = {Image Processing},
mendeley-tags = {Image Processing},
publisher = {Prentice Hall},
title = {{Digital Image Processing (3rd Edition)}},
year = {2007}
}

@inproceedings{Mukundan2013,
author = {Mukundan, J. and Hunter, H. and Kim, K-H and Stuecheli, J.},
booktitle = {ISCA},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/isca13-mukundan.pdf:pdf},
isbn = {9781450320795},
keywords = {refresh},
mendeley-tags = {refresh},
title = {{Understanding and Mitigating Refresh Overheads in High-Density DDR4 DRAM Systems}},
year = {2013}
}

@inproceedings{Stuecheli2010,
author = {Stuecheli, J and Kaseridis, D. and Hunter, H. and John, L.},
booktitle = {MICRO},
doi = {10.1109/MICRO.2010.22},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Elastic Refresh.pdf:pdf},
isbn = {978-1-4244-9071-4},
title = {{Elastic Refresh: Techniques to Mitigate Refresh Penalties in High Density Memory}},
year = {2010}
}

@article{Peters2007,
author = {Peters, R. and Itti, L.},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Peters\_Itti08tap.pdf:pdf},
journal = {ACM Trans. on Applied Perception},
title = {{Applying computational tools to predict gaze direction in interactive visual environments}},
year = {2007}
}

@article{Schrauwen2008,
author = {Schrauwen, B. and D'Haene, M. and Verstraeten, D. and Van Campenhout, Jan},
doi = {10.1016/j.neunet.2007.12.009},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Schrauwen et al.\_Compact hardware liquid state machines on FPGA for real-time speech recognition.\_2008.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
title = {{Compact hardware liquid state machines on FPGA for real-time speech recognition.}},
year = {2008}
}

@article{Irick2009,
author = {Irick, K. and others},
doi = {10.1117/12.834177},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Irick et al.\_A scalable multi-FPGA framework for real-time digital signal processing\_2009.pdf:pdf},
journal = {Proceedings of SPIE},
keywords = {fpga design,image processing},
title = {{A scalable multi-FPGA framework for real-time digital signal processing}},
year = {2009}
}

@article{Guo2010,
author = {Guo, C. and Zhang, L.},
doi = {10.1109/TIP.2009.2030969},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/Guo, Zhang\_A novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression.\_2010.pdf:pdf},
issn = {1941-0042},
journal = {IEEE Trans. on Image Processing},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{A Novel Multiresolution Spatiotemporal Saliency Detection Model and its Applications in Image and Video Compression}},
year = {2010}
}

@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/The Mendeley Support Team\_Getting Started with Mendeley\_2011.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
year = {2011}
}

@article{Koehler2014,
author = {Koehler, K. and Eckstein, M.},
doi = {10.1167/14.3.14.doi},
file = {:Users/siddharthadvani/Documents/Mendeley Desktop/What do saliency models predict.pdf:pdf},
journal = {Journal of Vision},
keywords = {Saliency},
mendeley-tags = {Saliency},
title = {{What do saliency models predict ?}},
year = {2014}
}

@misc{vivado,
      title  = "{Vivado Design Suite}",
      booktitle = "Xilinx",
      year   = "2014",
    }

@misc{jedec-sdram-standards,
      title  = "{JEDEC DDR3 and DDR4 SDRAM Standard}",
      booktitle = "JEDEC",
      year   = "2012",
    }


@article{Itti1998,
  author = {L. Itti and C. Koch and E. Niebur},
  title = {A Model of Saliency-Based Visual Attention for Rapid Scene Analysis},
  journal = {IEEE Trans. on Pattern Analysis and Machine Intelligence},
  year = {1998},
  keywords = {Visual attention ; target detection ; saliency ; image understanding},
  abstract = {A trainable visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.},
  type = {mod;bu;cv},
  file = {http://iLab.usc.edu/publications/doc/Itti_etal98pami.pdf},
  if = {1998 impact factor: 1.417},
}

@INPROCEEDINGS{Effex, 
author={Clemons, J. and Jones, A. and Perricone, R. and Savarese, S. and Austin, T.}, 
booktitle={Design Automation Conference (DAC), 2011 48th ACM/EDAC/IEEE}, 
title={EFFEX: An embedded processor for computer vision based feature extraction}, 
year={2011}, 
ISSN={0738-100x}}

@INPROCEEDINGS{Farabet, 
author={Farabet, C. and others}, 
booktitle={CVPRw}, 
title={NeuFlow: A runtime reconfigurable dataflow processor for vision}, 
year={2011}, 
keywords={computer vision;field programmable gate arrays;flow graphs;NeuFlow;Xilinx Virtex 6 FPGA platform;dataflow compiler;flow graph representations;laptop computer;luaFlow;machine code;runtime reconfigurable dataflow processor;scalable dataflow hardware architecture;Computer architecture;Convolvers;Feature extraction;Field programmable gate arrays;Hardware;Runtime;Tiles}, 
doi={10.1109/CVPRW.2011.5981829}, 
ISSN={2160-7508}}

@ARTICLE{DRAMSim2,
author={Rosenfeld, P. and Cooper-Balis, E. and Jacob, B.},
journal={Computer Architecture Letters}, 
title={{DRAMSim2}: A Cycle Accurate Memory System Simulator},
year={2011},
keywords={DDR2/3 memory system model;DRAMSim2 simulation;DRAMSim2 timing;Verilog model;cycle accurate memory system simulator;trace-based simulation;visualization tool;DRAM chips;memory architecture;memory cards;},
doi={10.1109/L-CA.2011.4},
ISSN={1556-6056},}


@INPROCEEDINGS{islped98, 
author={Ohsawa, T. and Kai, K. and Murakami, K.}, 
booktitle={ISLPED}, 
title={Optimizing the DRAM refresh count for merged {DRAM/logic LSIs}}, 
year={1998}, 
keywords={DRAM chips;circuit optimisation;integrated circuit design;integrated logic circuits;large scale integration;low-power electronics;memory architecture;DRAM refresh architectures;DRAM refresh count optimisation;data retention time;merged DRAM/logic LSIs;power consumption},}

@INPROCEEDINGS{action-recognition, 
author={Jhuang, H. and Serre, T. and Wolf, L. and Poggio, T.}, 
booktitle={ICCV}, 
title={A Biologically Inspired System for Action Recognition}, 
year={2007}, 
keywords={image motion analysis;image sequences;object recognition;video signal processing;action recognition;biologically inspired system;hierarchical feedforward architectures;motion processing;motion-direction sensitive units;neurobiological model;object recognition;position-invariant spatio-temporal feature detectors;video sequences;Biological system modeling;Brain modeling;Computer vision;Motion analysis;Motion detection;Object recognition;Position sensitive particle detectors;Sensor arrays;Testing;Video sequences}, 
doi={10.1109/ICCV.2007.4408988}, 
ISSN={1550-5499},}

@inproceedings{Weizmann,
  author	= {Moshe Blank and Lena Gorelick and Eli Shechtman and Michal Irani and Ronen Basri},
  title 	= {Actions as Space-Time Shapes},
  booktitle	= {ICCV},
  year   	= {2005},
  }

@article{refresh-pausing-taco2014,
 author = {Nair, P. and Chou, C. and Qureshi, M.},
 title = {Refresh Pausing in DRAM Memory Systems},
 journal = {TACO},
 year = {2014},
 doi = {10.1145/2579669},
} 


@INPROCEEDINGS{mcpat, 
author={Li, S. and others}, 
booktitle={MICRO}, 
title={{McPAT}: An integrated power, area, and timing modeling framework for multicore and manycore architectures}, 
year={2009}
}

@inproceedings{iccad,
author    = "M. Cotter and S. Advani and J. Sampson and K. Irick and V. Naryanan.",
title     = "A Hardware Accelerated Multilevel Visual Classifier for Embedded Visual-Assist Systems",
booktitle = "International Conference on Computer-Aided Design (ICCAD)",
year      = "2014",
month     = "November"
}

@INPROCEEDINGS{sips2014, 
author={Suleiman, A. and Sze, V.}, 
booktitle={IEEE Workshop on Signal Processing Systems}, 
title={{Energy-efficient HOG-based object detection at 1080HD 60 fps with multi-scale support}}, 
year={2014}, 
month={Oct}, 
}

@INPROCEEDINGS{HPCA2015,
author={Chandramoorthy, N. and others},
booktitle={HPCA},
title={{Exploring architectural heterogeneity in intelligent vision systems}},
year={2015},
month={Feb},
pages={1-12},
}

@INPROCEEDINGS{icassp2013,
author={Takagi, K. and Mizuno, K. and Izumi, S. and Kawaguchi, H. and Yoshimoto, M.},
title={{A sub-100-milliwatt dual-core HOG accelerator VLSI for real-time multiple object detection}},
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
year={2013},
month={May},
pages={2533-2537},
}

@INPROCEEDINGS{jetcas2013,
author={Blair, C. and Robertson, N.M. and Hume, D.},
journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
title={{Characterizing a Heterogeneous System for Person Detection in Video Using Histograms of Oriented Gradients: Power Versus Speed Versus Accuracy}},
year={2013},
month={June},
pages={236-247},
}

@INPROCEEDINGS{fccm2014, 
author={Ma, Xiaoyin and Najjar, Walid and Chowdhury, Amit Roy}, 
booktitle={Field-Programmable Custom Computing Machines (FCCM), 2014 IEEE 22nd Annual International Symposium on}, 
title={High-Throughput Fixed-Point Object Detection on FPGAs}, 
year={2014}, 
month={May}, 
pages={107-107}, 
}

@INPROCEEDINGS{ippro, 
author={Kelly, C. and Siddiqui, F.M. and Bardak, B. and Woods, R.}, 
booktitle={Signal Processing Systems (SiPS), 2014 IEEE Workshop on}, 
title={Histogram of oriented gradients front end processing: An FPGA based processor approach}, 
year={2014}, 
month={Oct}, 
pages={1-6}, 
}

@INPROCEEDINGS{cvpr_ws,
author={Hahnle, M. and Saxen, F. and Hisung, M. and Brunsmann, U. and Doll, K.},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition Workshops},
title={FPGA-Based Real-Time Pedestrian Detection on High-Resolution Images},
year={2013},
month={June},
pages={629-635},
}

@Misc{Caffe,
 author = {Caffe},
 howpublished = {\url{http://caffe.berkeleyvision.org/ }},
}

@INPROCEEDINGS{lpirc,
author={Y. H. Lu and A. M. Kadin and A. C. Berg and T. M. Conte and E. P. DeBenedictis and R. Garg and G. Gingade and B. Hoang and Y. Huang and B. Li and J. Liu and W. Liu and H. Mao and J. Peng and T. Tang and E. K. Track and J. Wang and T. Wang and Y. Wang and J. Yao},
booktitle={Computer-Aided Design (ICCAD), 2015 IEEE/ACM International Conference on},
title={Rebooting Computing and Low-Power Image Recognition Challenge},
year={2015},
pages={927-932},
month={Nov},
}

@incollection{NIPS2012,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Geoffrey E. Hinton},
booktitle = {Advances in Neural Information Processing Systems 25},
pages = {1097--1105},
year = {2012}
}

@article{libsvm,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 volume = {2},
 issue = {3},
 year = {2011},
 note =	 {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@INPROCEEDINGS{estimedia2014,
author={Ashouri, A.H. and Mariani, G. and Palermo, G. and Silvano, C.},
booktitle={Embedded Systems for Real-time Multimedia (ESTIMedia), 2014 IEEE 12th Symposium on},
title={{A Bayesian Network Approach for Compiler Auto-Tuning for Embedded Processors}},
year={2014},
month={Oct},
}

%@article{pascal,
 author = "Everingham, Mark and Gool, Luc and Williams, Christopher K. and Winn, John and Zisserman, Andrew",
 journal = "Int. J. Comput. Vision",
 title = "The Pascal Visual Object Classes (VOC) Challenge",
 year = "2010",
 month = "June"
}

@article{LabelMe,
 author = "Russell, B. and Torralba, A. and Murphy, K. and Freeman, W.",
 title = "LabelMe: A Database and Web-Based Tool for Image Annotation",
 journal = "Int. J. Comput. Vision",
 year = "2008",
 month = "May"
}

@inproceedings{BingObj2014,
  title={{{BING}: Binarized Normed Gradients for Objectness Estimation at 300fps}},
  author={Ming-Ming Cheng and Ziming Zhang and Wen-Yan Lin and Philip H. S. Torr},
  booktitle={IEEE CVPR},
  year={2014},
}

@INPROCEEDINGS{DATE2013, 
author={Xiao, Yang and Irick, Kevin and Narayanan, Vijaykrishnan and Shin, Donghwa and Chang, Naehyuck}, 
booktitle={Design, Automation Test in Europe Conference Exhibition (DATE), 2013}, 
title={{Saliency Aware Display Power Management}}, 
year={2013}, 
month={March}, 
pages={1203-1208}, 
}

@INPROCEEDINGS{Anggorosesar, 
author={Anggorosesar, A. and Young-Jin Kim}, 
booktitle={International Symposium on Low Power Electronics and Design}, 
title={{Object-based Local Dimming for LCD Systems with LED BLUs}}, 
year={2011}, 
month={Aug}, 
pages={315-320}, 
}

@article{Zappi,
 author = {Zappi, Piero and Roggen, Daniel and Farella, Elisabetta and Tr\"{o}ster, Gerhard and Benini, Luca},
 title = {{Network-Level Power-Performance Trade-Off in Wearable Activity Recognition: A Dynamic Sensor Selection Approach}},
 journal = {ACM Trans. Embed. Comput. Syst.},
 month = Sep,
 year = {2012},
}

@article{Chang2004, 
author={Naehyuck Chang and Inseok Choi and Hojun Shim}, 
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
title={{DLS: Dynamic Backlight Luminance Scaling of Liquid Crystal Display}}, 
year={2004}, 
month={Aug}, 
pages={837-846}, 
}

@article{Kyrkou2013,
 author = {Kyrkou, Christos and Ttofis, Christos and Theocharides, Theocharis},
 title = {{A Hardware Architecture for Real-time Object Detection Using Depth and Edge Information}},
 journal = {ACM Trans. Embed. Comput. Syst.},
 month = Dec,
 year = {2013},
 pages = {54:1--54:19},
}

@inproceedings{Dalton,
 author = {Dalton, Angela B. and Ellis, Carla S.},
 title = {{Sensing User Intention and Context for Energy Management}},
 booktitle = {Proceedings of the 9th Conference on Hot Topics in Operating Systems - Volume 9},
 year = {2003},
 pages = {26--26},
}

@INPROCEEDINGS{Moshnyaga, 
author={Moshnyaga, V.G. and Morikawa, E.}, 
booktitle={IEEE International Conference on Computer Design}, 
title={{LCD Display Energy Reduction by User Monitoring}}, 
year={2005}, 
month={Oct}, 
pages={94-97}, 
}

@ARTICLE{Oh2011, 
author={Daeyoun Cho and Won-Sik Oh and Gun-Woo Moon}, 
journal={Journal of Display Technology}, 
title={{A Novel Adaptive Dimming LED Backlight System With Current Compensated X-Y Channel Drivers for LCD TVs}}, 
year={2011}, 
month={Jan}, 
pages={29-35}, 
}

@ARTICLE{Lee2009, 
author={Lee, Wonbok and Patel, Kimish and Pedram, Massoud.}, 
journal={Journal of the Society for Information Display},
title={{White-LED Backlight Control for Motion-Blur reduction and Power Minimization in Large LCD TVs}},
year={2009},
month={Jan},
pages={37-45},
}

@ARTICLE{Giamello2010,
author={Noel Giamello},
title={{LED Backlighting for LCDs: Options, Design Consideration, and Benefits}},
year={2010},
month={Mar},
}

@INPROCEEDINGS{Cheng2006, 
author={Wei-Chung Cheng and Chih-Fu Hsu and Chain-Fu Chao}, 
booktitle={International Symposium on Low Power Electronics and Design}, 
title={{Temporal Vision-Guided Energy Minimization for Portable Displays}}, 
year={2006}, 
month={Oct}, 
pages={89-94}, 
}

@INPROCEEDINGS{Choi2002,
author={Inseok Choi and Hojun Shim and Naehyuck Chang},
booktitle={International Symposium on Low Power Electronics and Design},
title={{Low-power Color TFT LCD Display for Hand-held Embedded Systems}},
year={2002},
month={Oct},
pages={112-117},
}

@inproceedings{Gatti2002,
 author = {Gatti, Franco and Acquaviva, Andrea and Benini, Luca and Ricco', Bruno},
 title = {{Low Power Control Techniques For TFT LCD Displays}},
 booktitle = {Proceedings of the 2002 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems},
 year = {2002},
 pages = {218--224},
} 

@article{Kuon2007,
author={Ian Kuon and Rose, J.},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
title={{Measuring the Gap Between FPGAs and ASICs}},
year={2007},
month={Feb},
pages={203-215},
}

@INPROCEEDINGS{reva,
author={Advani, S. and Chandramoorthy, N. and Swaminathan, K. and Irick, K. and Cho, Y.C.P. and Sampson, J. and Narayanan, V.},
booktitle={Computer Design (ICCD), 2014 32nd IEEE International Conference on},
title={{Refresh Enabled Video Analytics (REVA): Implications on power and performance of DRAM supported embedded visual systems}},
year={2014},
month={Oct},
pages={501-504},
}

@ARTICLE{lcd_future,
author={Ishii, Y.},
journal={Journal of Display Technology},
title={{The World of Liquid-Crystal Display TVs - Past, Present, and Future}},
year={2007},
month={Dec},
volume={3},
number={4},
pages={351-360},
}

@misc{mit-saliency-benchmark,
  author       = {Zoya Bylinskii and others},
  title        = {MIT Saliency Benchmark},
  howpublished = {http://saliency.mit.edu/}
}

@misc{DiniV7,
  author       = {DINI-Group},
  title        = {{DNV7F2B}},
  howpublished = {http://www.dinigroup.com/web/DNV7F2B.php}
}

@ARTICLE{tvlsi2014,
author={Bapat, O.A. and Franzon, P.D. and Fastow, R.M.},
journal={Very Large Scale Integration (VLSI) Systems, IEEE Transactions on},
title={{A Generic and Scalable Architecture for a Large Acoustic Model and Large Vocabulary Speech Recognition Accelerator Using Logic on Memory}},
year={2014},
month={Dec},
volume={22},
number={12},
pages={2701-2712},
}

@ARTICLE{tvlsi2014_2,
author={Neil, D. and Shih-Chii Liu},
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
title={{Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator}},
year={2014},
month={Dec},
volume={22},
number={12},
pages={2621-2628},
}

@ARTICLE{IBMRetail2015, 
author={Marder, M. and Harary, S. and Ribak, A. and Tzur, Y. and Alpert, S. and Tzadok, A.}, 
journal={IBM Journal of Research and Development}, 
title={{Using Image Analytics to Monitor Retail Store Shelves}}, 
year={2015}, 
month={March}, 
volume={59}, 
number={2/3}, 
pages={3:1-3:11}, 
}

@INPROCEEDINGS{hop, 
author={Kokkinos, I. and Yuille, A.}, 
booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on}, 
title={{HOP: Hierarchical Object Parsing}}, 
year={2009}, 
month={June}, 
pages={802-809}
}

@INPROCEEDINGS{sift, 
author={Lowe, D.G.}, 
booktitle={Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on}, 
title={{Object Recognition from Local Scale-Invariant Features}}, 
year={1999}, 
month={}, 
volume={2}, 
pages={1150-1157 vol.2}
}

@INPROCEEDINGS{Farabet2009,
author={Farabet, C. and Poulet, C. and Han, J.Y. and LeCun, Y.},
booktitle={International Conference on Field Programmable Logic and Applications (FPL)},
title={{CNP: An FPGA-based processor for Convolutional Networks}},
year={2009},
month={Aug},
}

@ARTICLE{wearables2014,
author={Wei, J.},
journal={Consumer Electronics Magazine, IEEE},
title={{How Wearables Intersect with the Cloud and the Internet of Things : Considerations for the Developers of Wearables}},
year={2014},
month={July},
volume={3},
number={3},
pages={53-56},
}

@ARTICLE{wearables2014-2,
author={Starner, T.},
journal={Pervasive Computing, IEEE},
title={{How Wearables Worked their Way into the Mainstream}},
year={2014},
month={Oct},
volume={13},
number={4},
pages={10-15},
}

@ARTICLE{wearables2009, 
author={Amft, O. and Lukowicz, P.}, 
journal={Pervasive Computing, IEEE}, 
title={From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers}, 
year={2009}, 
month={July}, 
volume={8}, 
number={3}, 
pages={8-13}, 
}

@ARTICLE{wearables2008,
author={Mitchener, J.},
journal={Engineering Technology},
title={{What We'll Wear}},
year={2008},
month={October},
volume={3},
number={18},
pages={74-74},
}

@ARTICLE{context2012,
author={Lukowicz, P. and Nanda, S. and Narayanan, V. and Albelson, H. and McGuinness, D.L. and Jordan, M.I.},
journal={Pervasive Computing, IEEE},
title={Qualcomm Context-Awareness Symposium Sets Research Agenda for Context-Aware Smartphones},
year={2012},
month={January},
volume={11},
number={1},
pages={76-79},
}

@INPROCEEDINGS{bingcvpr2014,
author={Ming-Ming Cheng and Ziming Zhang and Wen-Yan Lin and Torr, P.},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
title={BING: Binarized Normed Gradients for Objectness Estimation at 300fps},
year={2014},
month={June},
pages={3286-3293},
}

@incollection{rogers,
author={Everett Rogers},
title={Diffusion of Innovations},
publisher={Free Press},
year={2003}
}

@incollection{RTV4HCI,
author={Branislav Kisacanin, Vladimir Pavlovic and Thomas Huang},
title={Real-time Vision for Human-Computer Interaction},
publisher={Springer},
year={2005}
}

@article{DNNNature2015,
author={LeCun, Y. and Bengio, Y. and Hinton, G.E.},
booktitle={Nature},
title={{Deep Learning}},
year={2015},
month={May},
pages={436-444}
}

@incollection{Bengio2009,
title = {{Learning Deep Architectures for AI}},
author = {Yoshua Bengio},
publisher = {Now Publishers},
year = {2009}
}

@ARTICLE{Iyer2011,
author={Iyer, R. and others},
journal={Micro, IEEE},
title={{CogniServe: Heterogeneous Server Architecture for Large-Scale Recognition}},
year={2011},
month={May}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@INPROCEEDINGS{DaDianNao, 
author={Yunji Chen and Tao Luo and Shaoli Liu and Shijin Zhang and Liqiang He and Jia Wang and Ling Li and Tianshi Chen and Zhiwei Xu and Ninghui Sun and Temam, O.}, 
booktitle={Microarchitecture (MICRO), 2014 47th Annual IEEE/ACM International Symposium on}, 
title={DaDianNao: A Machine-Learning Supercomputer}, 
year={2014}, 
month={Dec}, 
pages={609-622}
}

@INPROCEEDINGS{contextsips2014, 
author={Qinru Qiu and Zhe Li and Ahmed, K. and Hai Li and Miao Hu}, 
booktitle={Signal Processing Systems (SiPS), 2014 IEEE Workshop on}, 
title={{Neuromorphic Acceleration for Context Aware Text Image Recognition}}, 
year={2014}, 
month={Oct}, 
pages={1-6}
}

@ARTICLE{pervasive2015,
author={Amft, O. and Wahl, F. and Ishimaru, S. and Kunze, K.},
journal={Pervasive Computing, IEEE},
title={Making Regular Eyeglasses Smart},
year={2015},
month={July},
volume={14},
number={3},
pages={32-43},
}

@article{stein2009neural,
  title={{The Neural Basis of Multisensory Integration in the Midbrain: its Organization and Maturation}},
  author={Stein, Barry E and Stanford, Terrence R and Rowland, Benjamin A},
  journal={Hearing Research},
  volume={258},
  number={1},
  pages={4-15},
  year={2009}
}

@INPROCEEDINGS{svmvsrls, 
author={Peng Zhang and Jing Peng}, 
booktitle={Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on}, 
title={{SVM vs Regularized Least Squares Classification}}, 
year={2004}, 
month={Aug}, 
volume={1}, 
pages={176-179 Vol.1}
}

@INPROCEEDINGS{inis2015,
author={S. Advani and S. Kestur and V. Narayanan},
booktitle={2015 IEEE International Symposium on Nanoelectronic and Information Systems},
title={Intelligent Vision Systems: Exploring the State-of-the-Art and Opportunities for the Future},
year={2015},
pages={77-82},
month={Dec},
}

@INPROCEEDINGS{iccd2014,
author={Advani, S. and Chandramoorthy, N. and Swaminathan, K. and Irick, K. and Cho, Y.C.P. and Sampson, J. and Narayanan, V.},
booktitle={Computer Design (ICCD), 2014 32nd IEEE International Conference on},
title={Refresh Enabled Video Analytics (REVA): Implications on power and performance of DRAM supported embedded visual systems},
year={2014},
month={Oct},
pages={501-504},
}

@INPROCEEDINGS{chippa,
author={Chippa, V.K. and Mohapatra, D. and Raghunathan, A. and Roy, K. and Chakradhar, S.T.},
booktitle={Design Automation Conference (DAC), 2010 47th ACM/IEEE},
title={{Scalable Effort Hardware Design: Exploiting Algorithmic Resilience for Energy Efficiency}},
year={2010},
pages={555-560},
month={June},
}

@ARTICLE{temam2015,
author={Zidong Du and Lingamneni, A. and Yunji Chen and Palem, K.V. and Temam, O. and Chengyong Wu},
journal={Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on},
title={{Leveraging the Error Resilience of Neural Networks for Designing Highly Energy Efficient Accelerators}},
year={2015},
volume={34},
number={8},
pages={1223-1235},
month={Aug},
}

@article{chen2015fast,
  title={{A Fast Model for Analysis and Improvement of Gate-Level Circuit Reliability}},
  author={Chen, Chunhong and Xiao, Ran},
  journal={Integration, the VLSI Journal},
  year={2015}
}

@inproceedings{isca2015,
 author = {Bhati, Ishwar and Chishti, Zeshan and Lu, Shih-Lien and Jacob, Bruce},
 title = {{Flexible Auto-refresh: Enabling Scalable and Energy-efficient DRAM Refresh Reductions}},
 booktitle = {Proceedings of the 42Nd Annual International Symposium on Computer Architecture},
 year = {2015},
 pages = {235--246},
 numpages = {12},
} 

@article{poggio,
  author = {Riesenhuber, M and Poggio, Tomaso},
  journal = {Nature Neuroscience},
  number = 11,
  pages = {1019-1025},
  title = {{Hierarchical Models of Object Recognition in Cortex}},
  volume = 2,
  year = 1999
}

@INPROCEEDINGS{serre,
author={Serre, T. and Wolf, L. and Poggio, T.},
booktitle={Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on},
title={{Object Recognition with Features Inspired by Visual Cortex}},
year={2005},
volume={2},
pages={994-1000 vol. 2},
month={June},
}

@INPROCEEDINGS{kesturdac, 
author={Kestur, S. and Irick, K. and Sungho Park and Al Maashri, A. and Narayanan, V. and Chakrabarti, C.}, 
booktitle={Design Automation Conference (DAC), 2011 48th ACM/EDAC/IEEE}, 
title={{An Algorithm-Architecture Co-Design Framework for Gridding Reconstruction using FPGAs}}, 
year={2011}, 
pages={585-590}, 
month={June},
}

@incollection{IPHandbook,
author = {Russ, J.},
title = {{The Image Processing Handbook}},
year = {2011},
publisher = {CRC Press},
}

@ARTICLE{Keys, 
author={Keys, R.}, 
journal={Acoustics, Speech and Signal Processing, IEEE Transactions on}, 
title={{Cubic Convolution Interpolation for Digital Image Processing}}, 
year={1981}, 
volume={29}, 
number={6}, 
pages={1153-1160}, 
month={Dec},
}

@ARTICLE{hexagon,
author={Codrescu, L. and others},
journal={Micro, IEEE},
title={{Hexagon DSP: An Architecture Optimized for Mobile Multimedia and Communications}},
year={2014},
volume={34},
number={2},
pages={34-43},
month={Mar},
}

@INPROCEEDINGS{micro2010, 
author={Chung, E.S. and Milder, P.A. and Hoe, J.C. and Ken Mai}, 
booktitle={Microarchitecture (MICRO), 2010 43rd Annual IEEE/ACM International Symposium on}, 
title={{Single-Chip Heterogeneous Computing: Does the Future Include Custom Logic, FPGAs, and GPGPUs?}}, 
year={2010}, 
pages={225-236}, 
month={Dec},
}

@INPROCEEDINGS{violafccm,
author={Hefenbrock, D. and Oberg, J. and Nhat Thanh and Kastner, R. and Baden, S.B.},
booktitle={Field-Programmable Custom Computing Machines (FCCM), 2010 18th IEEE Annual International Symposium on},
title={{Accelerating Viola-Jones Face Detection to FPGA-Level Using GPUs}},
year={2010},
pages={11-18},
month={May},
}

@INPROCEEDINGS{micro2008,
author={Mahesri, A. and Johnson, D. and Crago, N. and Patel, S.J.},
booktitle={Microarchitecture, 2008. MICRO-41. 2008 41st IEEE/ACM International Symposium on},
title={{Tradeoffs in Designing Accelerator Architectures for Visual Computing}},
year={2008},
pages={164-175},
month={Nov},
}

@INPROCEEDINGS{giles1997,
author={Lawrence, S. and Giles, C.L. and Ah Chung Tsoi},
booktitle={Computer Vision and Pattern Recognition, 1996. Proceedings CVPR '96, 1996 IEEE Computer Society Conference on},
title={{Convolutional Neural Networks for Face Recognition}},
year={1996},
pages={217-222},
month={Jun},
}

@electronic{XilinxCNN,
 author={XCell},
 title={{Machine Learning in the Cloud: Deep Neural Networks on FPGAs}},
 url={http://issuu.com/xcelljournal/docs/xcell_journal_issue_92/46?e},
 note={(Date last accessed 30-May-2016)}
}

@inproceedings{ISCA2010,
   author              = {Srimat T. Chakradhar and 
                          Murugan Sankaradass and 
                          Venkata Jakkula and 
                          Srihari Cadambi},
   title               = {{A Dynamically Configurable Coprocessor for Convolutional Neural Networks}},
   booktitle           = {ISCA},
   year                = {2010},
   pages               = {247-257},
}

@incollection{NIPS2014,
title = {{How Transferable are Features in Deep Neural Networks?}},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
booktitle = {Advances in Neural Information Processing Systems 27},
pages = {3320--3328},
year = {2014},
}

@article{karam2016,
  author    = {Samuel F. Dodge and Lina J. Karam},
  title     = {Understanding How Image Quality Affects Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1604.04004},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.04004},
  timestamp = {Mon, 02 May 2016 18:22:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/DodgeK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{capi,
author={J. Stuecheli and B. Blaner and C. R. Johns and M. S. Siegel},
journal={IBM Journal of Research and Development},
title={CAPI: A Coherent Accelerator Processor Interface},
year={2015},
volume={59},
number={1},
pages={7:1-7:7},
month={Jan}
}

@INPROCEEDINGS{sampson2006,
author={C. Lemuet and J. Sampson and J. Francois and N. Jouppi},
booktitle={SC 2006 Conference, Proceedings of the ACM/IEEE},
title={The Potential Energy Efficiency of Vector Acceleration},
year={2006},
pages={1-1},
month={Nov},
}

@article{facenet,
  author    = {Florian Schroff and
               Dmitry Kalenichenko and
               James Philbin},
  title     = {FaceNet: {A} Unified Embedding for Face Recognition and Clustering},
  journal   = {CoRR},
  volume    = {abs/1503.03832},
  year      = {2015},
  url       = {http://arxiv.org/abs/1503.03832},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SchroffKP15},
}

@INPROCEEDINGS{Csurka04,
    author = {Gabriella Csurka and Christopher R. Dance and Lixin Fan and Jutta Willamowski and Cédric Bray},
    title = {Visual categorization with bags of keypoints},
    booktitle = {In Workshop on Statistical Learning in Computer Vision, ECCV},
    year = {2004},
    pages = {1--22}
}

@INPROCEEDINGS{gpu2008,
author={J. Michalakes and M. Vachharajani},
booktitle={Parallel and Distributed Processing, 2008. IPDPS 2008. IEEE International Symposium on},
title={GPU acceleration of numerical weather prediction},
year={2008},
pages={1-7},
month={April},
}

@INPROCEEDINGS{gpu2015, 
author={A. Angelova and A. Krizhevsky and V. Vanhoucke}, 
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Pedestrian detection with a Large-Field-Of-View deep network}, 
year={2015}, 
pages={704-711}, 
month={May},
}

@INPROCEEDINGS{mutlu_isca2012,
author={R. Ausavarungnirun and K. K. W. Chang and L. Subramanian and G. H. Loh and O. Mutlu},
booktitle={Computer Architecture (ISCA), 2012 39th Annual International Symposium on},
title={Staged memory scheduling: Achieving high performance and scalability in heterogeneous systems},
year={2012},
pages={416-427},
month={June},
}

@INPROCEEDINGS{vortex,
author={Sungho Park and Yong Cheol Peter Cho and K. M. Irick and V. Narayanan},
booktitle={17th Asia and South Pacific Design Automation Conference},
title={A reconfigurable platform for the design and verification of domain-specific accelerators},
year={2012},
pages={108-113},
month={Jan},
}

@InProceedings{Borji_2016_CVPR,
author = {Borji, Ali and Izadi, Saeed and Itti, Laurent},
title = {iLab-20M: A Large-Scale Controlled Object Dataset to Investigate Deep Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
} 

@inproceedings{vslam,
author = {C. Kerl, J. Sturm and D. Cremers}, 
title = {Robust Odometry Estimation for RGB-D Cameras}, 
booktitle = {IEEE International Conference on Intelligent Robot Systems}, 
month = {May},
year = {2013}
}

@inproceedings{emery2010development,
  title={Development of 3-D range imaging system to scan peach branches for selective robotic blossom thinning},
  author={Emery, Katrina G and Faubion, Drew M and Walsh, Christopher S and Tao, Yang},
  booktitle={2010 Pittsburgh, Pennsylvania, June 20-June 23, 2010},
  pages={1},
  year={2010},
  organization={American Society of Agricultural and Biological Engineers}
}

@inproceedings{deepcompression,
 title={Deep Compression: Compressing Deep Neural Networks With Pruning, Trained Quantization and Huffman Coding},
 author={Song Han, Huizi Mao and William Dally},
 booktitle={CoRR, abs/1510.00149},
 volume={2},
 year={2015}
 }

@article{shih2015use,
  title={Use and adoption challenges of wearable activity trackers},
  author={Shih, Patrick C and Han, Kyungsik and Poole, Erika Shehan and Rosson, Mary Beth and Carroll, John M},
  journal={iConference 2015 Proceedings},
  year={2015},
  publisher={iSchools}
}

@INPROCEEDINGS{estimedia2015,
author={Advani, S. and Smith, B. and Tanabe, Y. and Irick, K. and Cotter, M. and Sampson, J. and Narayanan, V.}, 
booktitle={Embedded Systems For Real-time Multimedia (ESTIMedia), 2015 13th IEEE Symposium on}, 
title={Visual Co-occurrence Network: Using Context for Large-Scale Object Recognition in Retail}, 
year={2015},
month={Oct},
pages={1-10},
}

@INPROCEEDINGS{iccad2014,
author={Cotter, M. and Advani, S. and Sampson, J. and Irick, K. and Narayanan, V.},
booktitle={Computer-Aided Design (ICCAD), 2014 IEEE/ACM International Conference on},
title={A hardware accelerated multilevel visual classifier for embedded visual-assist systems},
year={2014},
month={Nov},
pages={96-100},
}

@ARTICLE{truenorth,
author={F. Akopyan and others},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
title={TrueNorth: Design and Tool Flow of a 65 mW 1 Million Neuron Programmable Neurosynaptic Chip},
year={2015},
volume={34},
number={10},
pages={1537-1557},
month={Oct},
}

@inproceedings{redeye,
author={Robert LiKamWa and Yunhui Hou and Julian Gao and Mia Polansky and Lin Zhong},
booktitle={International Symposium on Computer Architecture},
title={RedEye: Analog ConvNet Image Sensor Architecture for Continuous Mobile Vision},
year={2016}
}

@ARTICLE{wtsai, 
author={W. Y. Tsai and others}, 
journal={IEEE Transactions on Multi-Scale Computing Systems}, 
title={Enabling New Computation Paradigms with HyperFET - An Emerging Device}, 
year={2016}, 
volume={2}, 
number={1}, 
pages={30-48}, 
month={Jan},
}

@INPROCEEDINGS{upitt, 
author={J. A. Carpenter and Y. Fang and C. N. Gnegy and D. M. Chiarulli and S. P. Levitan}, 
booktitle={2014 14th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)}, 
title={An image processing pipeline using coupled oscillators}, 
year={2014}, 
pages={1-2}, 
month={July},
}

@INPROCEEDINGS{fpl2015, 
author={Advani, Siddharth and Tanabe, Yasuki and Irick, Kevin and Sampson, Jack and Narayanan, Vijaykrishnan}, 
booktitle={Field Programmable Logic and Applications (FPL), 2015 25th International Conference on}, 
title={A scalable architecture for multi-class visual object detection}, 
year={2015}, 
month={Sept},
pages={1-8}, 
}
